# Phase 2 : Optimisations GPU et AvancÃ©es

## ğŸ“‹ Contexte

**Phase 1 (COMPLÃ‰TÃ‰E)** :
- âœ… Hyperthreading optimisÃ© (Ã—1.5 cores)
- âœ… Denoising adaptatif
- âœ… PrÃ©-chargement images en mÃ©moire
- âœ… **Gain : -25% du temps total**

**Phase 2 (PLANIFIÃ‰E)** :
- ğŸ¯ Utilisation GPU (OpenCV CUDA/OpenCL)
- ğŸ¯ Batch processing Tesseract
- ğŸ¯ Optimisations mÃ©moire avancÃ©es
- ğŸ¯ **Objectif : Gain additionnel de -30 Ã  -40%**

---

## ğŸ¯ Objectifs de la Phase 2

### **RÃ©duction du temps par image :**
- **Actuel** : ~1.5s par trial (24 images en parallÃ¨le)
- **Cible Phase 2** : ~1.0s par trial
- **Gain cumulÃ© Phases 1+2** : **-50 Ã  -60%** du temps initial

### **Temps d'optimisation projetÃ©s :**

| ScÃ©nario | Temps Actuel | Temps Cible Phase 2 |
|----------|--------------|---------------------|
| Screening 512 pts | 12.8 min | **8.5 min** |
| Screening 1024 pts | 25.6 min | **17 min** |
| Optuna 500 trials | 12.5 min | **8.3 min** |

---

## ğŸš€ Optimisations PrÃ©vues

### **1. Migration vers UMat (OpenCL GPU)** â­ PRIORITÃ‰ 1

#### **Principe :**
- Utiliser `cv2.UMat` au lieu de `np.ndarray` pour les images
- Les opÃ©rations OpenCV utilisent automatiquement le GPU si disponible
- Transparent pour le code (API identique)

#### **ImplÃ©mentation :**

**Modifications dans `gui_optimizer_v3_ultim.py` :**

```python
# Ligne 326 - PrÃ©-chargement des images
def pre_load_images(self):
    self.update_log_from_thread("PrÃ©-chargement des images en mÃ©moire (GPU)...")
    self.loaded_images = []

    for f in self.image_files:
        # Charger en UMat pour GPU
        img_cpu = cv2.imread(f, cv2.IMREAD_GRAYSCALE)
        if img_cpu is not None:
            img_gpu = cv2.UMat(img_cpu)  # Transfert vers GPU
            self.loaded_images.append(img_gpu)

    self.update_log_from_thread(f"{len(self.loaded_images)} images chargÃ©es en GPU memory.")
```

**Avantages :**
- âœ… GaussianBlur accÃ©lÃ©rÃ© (normalisation)
- âœ… Morphological operations accÃ©lÃ©rÃ©es (line removal)
- âœ… adaptiveThreshold accÃ©lÃ©rÃ© (binarisation)
- âœ… **Aucun changement de code** dans le pipeline (API identique)

**Limitations :**
- âš ï¸ `fastNlMeansDenoising` : Peut ne pas Ãªtre accÃ©lÃ©rÃ© selon la version OpenCV
- âš ï¸ Tesseract ne supporte pas UMat â†’ Conversion nÃ©cessaire avant OCR

#### **Code dÃ©taillÃ© :**

```python
def pipeline_complet(image, params):
    # image est dÃ©jÃ  un UMat (GPU)

    # Ã‰tape 1 : Line removal (GPU)
    no_lines = remove_lines_param(image, params['line_h_size'],
                                   params['line_v_size'], params['dilate_iter'])

    # Ã‰tape 2 : Normalisation (GPU)
    norm = normalisation_division(no_lines, params['norm_kernel'])

    # Ã‰tape 3 : Denoising (CPU ou GPU selon implÃ©mentation OpenCV)
    denoised = adaptive_denoising(norm, params['denoise_h'],
                                   params.get('noise_threshold', 100))

    # Ã‰tape 4 : Binarisation (GPU)
    binarized = cv2.adaptiveThreshold(denoised, 255,
                                      cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                      cv2.THRESH_BINARY,
                                      params['bin_block_size'], params['bin_c'])

    # Conversion UMat â†’ numpy pour Tesseract
    return binarized.get()  # Transfert GPU â†’ CPU
```

**Gain estimÃ© :** **+15-20%** sur les Ã©tapes 1, 2, 4

---

### **2. Optimisation Tesseract** â­ PRIORITÃ‰ 2

#### **Option A : Batch Processing (RECOMMANDÃ‰)**

**Principe :**
- Grouper les 24 images en un seul appel Tesseract
- RÃ©duire l'overhead de dÃ©marrage de Tesseract

**ImplÃ©mentation :**

```python
def process_images_batch(images_list, params):
    """
    Traite un batch d'images en une seule fois.
    RÃ©duit l'overhead de Tesseract (dÃ©marrage, chargement modÃ¨le).
    """
    # Preprocessing de toutes les images
    processed_images = []
    for img in images_list:
        processed = pipeline_complet(img, params)
        processed_images.append(processed)

    # CrÃ©er un "pseudo-PDF" multi-pages en mÃ©moire
    # ou appeler Tesseract une seule fois avec toutes les images

    # MÃ©thode 1 : Fichier temporaire multi-pages
    import tempfile
    with tempfile.NamedTemporaryFile(suffix='.tiff', delete=False) as tmp:
        # Sauvegarder toutes les images en TIFF multi-pages
        cv2.imwritemulti(tmp.name, processed_images)

        # Un seul appel Tesseract
        data = pytesseract.image_to_data(tmp.name, output_type=pytesseract.Output.DICT)

        # Parser les rÃ©sultats par page
        scores = parse_multipage_results(data)

    return scores
```

**Gain estimÃ© :** **+5-10%** (rÃ©duction overhead)

**ComplexitÃ© :** Moyenne (gestion multi-pages)

---

#### **Option B : RÃ©duction de rÃ©solution intelligente**

**Principe :**
- Redimensionner les images UNIQUEMENT pour Tesseract
- Garder rÃ©solution native pour preprocessing

**ImplÃ©mentation :**

```python
def get_tesseract_score(image):
    """Version optimisÃ©e avec resize systÃ©matique."""
    # Tesseract est plus rapide sur images < 2000px de largeur
    h, w = image.shape[:2]

    if w > 2000:
        scale = 2000 / w
        resized = cv2.resize(image, None, fx=scale, fy=scale,
                            interpolation=cv2.INTER_AREA)
    else:
        resized = image

    try:
        data = pytesseract.image_to_data(resized, config='--oem 1 --psm 6',
                                         output_type=pytesseract.Output.DICT)
        confs = [int(x) for x in data['conf'] if int(x) != -1]
        return sum(confs) / len(confs) if confs else 0
    except:
        return 0
```

**Gain estimÃ© :** **+10-15%** si images > 2000px
**Impact OCR :** Minimal (<1-2% de dÃ©gradation)

---

#### **Option C : Tesseract GPU (CUDA)** ğŸ”¥ MAXIMUM

**Principe :**
- Compiler Tesseract avec support CUDA
- OCR accÃ©lÃ©rÃ© par GPU

**ImplÃ©mentation :**
```bash
# Installation (complexe)
# 1. Installer CUDA Toolkit 11.x
# 2. Compiler Tesseract from source avec flag CUDA
# 3. Compiler pytesseract compatible

# Configuration
export TESSDATA_PREFIX=/usr/share/tesseract-ocr/4.00/tessdata/
export OMP_THREAD_LIMIT=1  # Important pour ne pas confliter avec multiprocessing
```

**Gain estimÃ© :** **+60-70%** sur l'Ã©tape OCR (857ms â†’ 260ms)
**ComplexitÃ© :** **TRÃˆS Ã‰LEVÃ‰E** (compilation, compatibilitÃ©)

**Recommandation :** **Ã‰viter sauf besoin critique** (gain Phase 2A+2B suffit)

---

### **3. Cache Preprocessing (Optionnel)** â­ PRIORITÃ‰ 3

#### **Principe :**
- Si les mÃªmes images sont utilisÃ©es, cacher les rÃ©sultats du preprocessing
- Utile si vous optimisez UNIQUEMENT `bin_c` par exemple

**ImplÃ©mentation :**

```python
class PreprocessingCache:
    def __init__(self):
        self.cache = {}  # {(img_id, params_hash): processed_img}

    def get_or_compute(self, img_id, params, compute_fn):
        # Hash des paramÃ¨tres qui affectent le preprocessing
        cache_params = {
            'line_h_size': params['line_h_size'],
            'line_v_size': params['line_v_size'],
            'norm_kernel': params['norm_kernel'],
            'denoise_h': params['denoise_h'],
            'noise_threshold': params.get('noise_threshold', 100)
        }

        key = (img_id, hash(frozenset(cache_params.items())))

        if key not in self.cache:
            self.cache[key] = compute_fn()

        return self.cache[key]
```

**Cas d'usage :**
- Optimisation de `bin_c` et `bin_block_size` UNIQUEMENT
- Les Ã©tapes 1-3 (line removal, normalisation, denoising) sont cachÃ©es

**Gain estimÃ© :** **+20-30%** si applicable
**Limitation :** Seulement si paramÃ¨tres preprocessing fixÃ©s

---

### **4. Optimisations MÃ©moire** â­ PRIORITÃ‰ 4

#### **A. Pool size dynamique selon RAM disponible**

```python
import psutil

def get_optimal_pool_size(n_images):
    # Mesurer RAM disponible
    available_ram = psutil.virtual_memory().available / (1024**3)  # GB

    # Estimer RAM par worker (image + processing)
    ram_per_worker = 0.5  # GB (Ã  ajuster selon vos images)

    max_workers_by_ram = int(available_ram / ram_per_worker)
    max_workers_by_cpu = int(os.cpu_count() * 1.5)

    optimal = min(n_images, max_workers_by_ram, max_workers_by_cpu)

    print(f"Pool size optimal: {optimal} (RAM: {max_workers_by_ram}, CPU: {max_workers_by_cpu})")

    return optimal
```

**Gain :** Ã‰vite les swaps mÃ©moire (stabilitÃ©)

---

#### **B. LibÃ©ration mÃ©moire explicite**

```python
import gc

def process_image_data_wrapper(args):
    # ... traitement ...

    result = (score_tess, score_sharp, score_cont)

    # LibÃ©ration explicite
    del processed_img, timings
    gc.collect()

    return result
```

**Gain :** RÃ©duit la pression mÃ©moire (utile si beaucoup d'images)

---

## ğŸ“Š RÃ©capitulatif des Gains EstimÃ©s

| Optimisation | Gain EstimÃ© | ComplexitÃ© | Recommandation |
|--------------|-------------|------------|----------------|
| **UMat (OpenCL)** | +15-20% | Faible | â­â­â­ OUI |
| **Batch Tesseract** | +5-10% | Moyenne | â­â­ Si besoin |
| **Resize Tesseract** | +10-15% | Faible | â­â­â­ OUI |
| **Tesseract CUDA** | +60-70% (OCR) | TrÃ¨s Ã©levÃ©e | âŒ NON (overkill) |
| **Cache Preprocessing** | +20-30% | Moyenne | â­ Cas spÃ©cifique |
| **Pool dynamique RAM** | StabilitÃ© | Faible | â­â­ OUI |

### **Combinaison RecommandÃ©e (Phase 2A) :**
âœ… UMat (OpenCL)
âœ… Resize Tesseract
âœ… Pool dynamique RAM

**Gain cumulÃ© attendu :** **-30%**
**ComplexitÃ© :** Faible Ã  moyenne
**Temps de dev :** 1-2 jours

---

## ğŸ› ï¸ Plan d'ImplÃ©mentation

### **Ã‰tape 1 : Tests PrÃ©liminaires**
1. VÃ©rifier que OpenCL fonctionne :
   ```python
   import cv2
   print(f"OpenCL disponible : {cv2.ocl.haveOpenCL()}")
   print(f"Device : {cv2.ocl.Device.getDefault().name()}")
   ```

2. Benchmark UMat vs numpy :
   ```python
   import time
   img_cpu = cv2.imread('test.jpg', cv2.IMREAD_GRAYSCALE)
   img_gpu = cv2.UMat(img_cpu)

   # Test GaussianBlur
   t0 = time.time()
   blurred_cpu = cv2.GaussianBlur(img_cpu, (51, 51), 0)
   print(f"CPU : {(time.time()-t0)*1000:.2f}ms")

   t0 = time.time()
   blurred_gpu = cv2.GaussianBlur(img_gpu, (51, 51), 0)
   result = blurred_gpu.get()  # Force GPU sync
   print(f"GPU : {(time.time()-t0)*1000:.2f}ms")
   ```

### **Ã‰tape 2 : Migration Progressive**
1. **Jour 1** : UMat pour prÃ©-chargement uniquement (test)
2. **Jour 2** : Resize Tesseract systÃ©matique
3. **Jour 3** : Pool dynamique RAM
4. **Jour 4** : Tests et mesures de gains rÃ©els

### **Ã‰tape 3 : Validation**
- Comparer scores OCR avant/aprÃ¨s (doivent Ãªtre identiques Â±1%)
- Mesurer temps par trial (gain attendu ~30%)
- VÃ©rifier stabilitÃ© (pas de crashes mÃ©moire)

---

## âš ï¸ Points d'Attention

### **UMat et Multiprocessing :**
```python
# ATTENTION : UMat n'est PAS pickle-able
# Il faut convertir en numpy avant de passer au pool

def pre_load_images(self):
    # Charger en numpy (CPU)
    for f in self.image_files:
        img = cv2.imread(f, cv2.IMREAD_GRAYSCALE)
        self.loaded_images.append(img)

    # Dans le worker, convertir en UMat
def process_image_data_wrapper(args):
    img_cpu, params = args
    img_gpu = cv2.UMat(img_cpu)  # Conversion dans chaque worker
    # ... traitement avec img_gpu ...
```

### **Tesseract et UMat :**
```python
# Tesseract ne supporte PAS UMat
# Conversion obligatoire avant OCR
processed_umat = pipeline_complet(img_gpu, params)
processed_numpy = processed_umat.get()  # UMat â†’ numpy
score = get_tesseract_score(processed_numpy)
```

---

## ğŸ“ Ressources et RÃ©fÃ©rences

### **Documentation OpenCV :**
- UMat : https://docs.opencv.org/4.x/d7/d60/classcv_1_1UMat.html
- OpenCL : https://docs.opencv.org/4.x/d7/d9f/tutorial_linux_install.html

### **Benchmarks GPU vs CPU :**
- GaussianBlur : 2-3Ã— plus rapide sur GPU
- morphologyEx : 1.5-2Ã— plus rapide
- adaptiveThreshold : 1.5-2Ã— plus rapide
- fastNlMeansDenoising : Peut Ãªtre plus LENT sur GPU (selon version)

### **Hardware Compatible :**
- âœ… NVIDIA (CUDA + OpenCL)
- âœ… AMD (OpenCL)
- âœ… Intel integrated GPU (OpenCL)

---

## ğŸ“‹ Checklist Phase 2

### **Avant de commencer :**
- [ ] VÃ©rifier OpenCL disponible (`cv2.ocl.haveOpenCL()`)
- [ ] Benchmarker 1 opÃ©ration GPU vs CPU
- [ ] Sauvegarder le code actuel (branch)

### **ImplÃ©mentation :**
- [ ] Migrer prÃ©-chargement vers UMat
- [ ] Ajouter conversion UMat dans workers
- [ ] ImplÃ©menter resize systÃ©matique Tesseract
- [ ] Ajouter pool size dynamique (RAM)

### **Tests :**
- [ ] VÃ©rifier scores OCR identiques
- [ ] Mesurer gains rÃ©els sur 64 points
- [ ] VÃ©rifier utilisation GPU (nvidia-smi ou radeontop)
- [ ] Tester avec 1024 points (stabilitÃ©)

### **Documentation :**
- [ ] Mettre Ã  jour gemini.md
- [ ] Ajouter notes de performance
- [ ] Documenter les gains obtenus

---

## ğŸ¯ DÃ©cision : ImplÃ©menter ou Non ?

### **Phase 2 est OPTIONNELLE si :**
- âœ… Phase 1 suffit (12-13 min pour 512 points acceptable)
- âœ… Pas besoin de screenings > 1024 points rÃ©guliÃ¨rement
- âœ… ComplexitÃ© ajoutÃ©e pas justifiÃ©e

### **Phase 2 est RECOMMANDÃ‰E si :**
- ğŸ¯ Besoin de screenings frÃ©quents (plusieurs par jour)
- ğŸ¯ Besoin de screenings larges (2^11 = 2048 points)
- ğŸ¯ GPU disponible mais sous-utilisÃ©
- ğŸ¯ Recherche du temps minimal absolu

---

## ğŸ’¡ Conclusion

**Phase 1 SEULE** apporte dÃ©jÃ  **-25%** de gain â†’ **EXCELLENT**

**Phase 2** peut ajouter **-30%** supplÃ©mentaires avec effort modÃ©rÃ©

**Recommandation** :
1. **Tester Phase 1** sur PC de bureau avec screening 512 points
2. **Mesurer si le temps actuel est acceptable** pour votre usage
3. **DÃ©cider ensuite** si Phase 2 vaut l'investissement

**Mon avis** : Phase 1 suffit largement pour la plupart des cas d'usage ! ğŸ¯

---

*Document crÃ©Ã© le 2025-11-27 - RÃ©fÃ©rence pour implÃ©mentation future*
